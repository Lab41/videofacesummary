{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# URL of http video stream\n",
    "url = ''\n",
    "# Set number of seconds to retrieve images from http video stream\n",
    "run_time = 60\n",
    "# Set range of upsampling to do on image while calling face.face_locations\n",
    "upsampling = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import glob\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "import urllib\n",
    "from collections import defaultdict\n",
    "from os.path import join\n",
    "from urllib.request import urlopen\n",
    "import dlib\n",
    "import face_recognition_models\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import cv2\n",
    "from face import face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get single frame from http video stream url\n",
    "try:\n",
    "    with urlopen(url) as stream:\n",
    "        data=b''\n",
    "        img = None\n",
    "        i = None\n",
    "        done = False\n",
    "        while not done:\n",
    "            data+=stream.read(1024) \n",
    "            a = data.find(b'\\xff\\xd8')\n",
    "            b = data.find(b'\\xff\\xd9')\n",
    "            if a!=-1 and b!=-1:\n",
    "                jpg = data[a:b+2]\n",
    "                data = data[b+2:]\n",
    "                i = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8),cv2.IMREAD_COLOR)\n",
    "                i2 = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
    "                img = Image.fromarray(i2)\n",
    "                done = True\n",
    "except urllib.error.HTTPError as HTTPError:\n",
    "    print(\"HTTPError; Wait and try again.\")\n",
    "except urllib.error.URLError as URLError:\n",
    "    print(\"URLError; Check url.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze single frame for faces\n",
    "im_arr = np.fromstring(img.tobytes(), dtype=np.uint8)\n",
    "im_arr = im_arr.reshape((img.size[1], img.size[0], 3))\n",
    "for level in upsampling:\n",
    "    print(\"Trying upsampling:\",level)\n",
    "    list_face_locations = face.face_locations(im_arr,level)\n",
    "    list_face_encodings = face.face_encodings(im_arr , list_face_locations)\n",
    "    for face_encoding, face_location in zip(list_face_encodings, list_face_locations):\n",
    "        (top, right, bottom, left) = face_location\n",
    "        cv2.rectangle(im_arr, (left, top),(right,bottom), (0, 255, 0), 2)\n",
    "        print('found face', face_location)\n",
    "    if len(list_face_locations)>0: \n",
    "        cv2.cvtColor(im_arr, cv2.COLOR_BGR2RGB)\n",
    "        #cv2.imwrite(\"/in/test.jpg\",im_arr)\n",
    "        image_boxes = Image.fromarray(im_arr)\n",
    "        from IPython.display import display\n",
    "        display(image_boxes)\n",
    "        break\n",
    "    else:\n",
    "        print(\"No faces found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeatedly pull images from url stream for a set period of time and scan for faces\n",
    "\n",
    "def getImage(url):\n",
    "    try:\n",
    "        with urlopen(url) as stream:\n",
    "            data = b''\n",
    "            img = None\n",
    "            i = None\n",
    "            done = False\n",
    "            while not done:\n",
    "                data += stream.read(1024)\n",
    "                start = data.find(b'\\xff\\xd8')\n",
    "                end = data.find(b'\\xff\\xd9')\n",
    "                if start != -1 and end != -1:\n",
    "                    jpg = data[start:end + 2]\n",
    "                    data = data[end + 2:]\n",
    "                    i = cv2.imdecode(np.fromstring(\n",
    "                        jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "                    i2 = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
    "                    img = Image.fromarray(i2)\n",
    "                    done = True\n",
    "            return img\n",
    "    except urllib.error.HTTPError as HTTPError:\n",
    "        print(\"HTTPError; Wait and try again.\")\n",
    "    except urllib.error.URLError as URLError:\n",
    "        print(\"URLError; Check url.\")\n",
    "    \n",
    "def findCameraFace(url, sleep, end):\n",
    "    found_people = []\n",
    "    print(\"Frame at\", time.asctime( time.localtime(time.time()) ))\n",
    "    img = getImage(url)         \n",
    "    im_arr = np.fromstring(img.tobytes(), dtype=np.uint8)\n",
    "    im_arr = im_arr.reshape((img.size[1], img.size[0], 3))\n",
    "    for level in upsampling:\n",
    "        #print(\"Trying upsampling:\",level)\n",
    "        list_face_locations = face.face_locations(im_arr,level)\n",
    "        list_face_encodings = face.face_encodings(im_arr , list_face_locations)\n",
    "        for face_encoding, face_location in zip(list_face_encodings, list_face_locations):\n",
    "            (top, right, bottom, left) = face_location\n",
    "            cv2.rectangle(im_arr, (left, top),(right,bottom), (0, 255, 0), 2)\n",
    "            print('found face', face_location)\n",
    "        if len(list_face_locations)>0: \n",
    "            found_people.append((img, im_arr, list_face_locations, list_face_encodings))\n",
    "            return found_people    \n",
    "    time.sleep(sleep)\n",
    "    return []\n",
    "\n",
    "found_people = []        \n",
    "start = int(time.time())\n",
    "end = start + run_time\n",
    "\n",
    "while int(time.time()) <= end:\n",
    "    found_people += findCameraFace(url, 0, end)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycles every 2 seconds through detected faces on images from http video stream\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "for person in range(len(found_people)):\n",
    "    clear_output(wait=True)\n",
    "    im_arr = found_people[person][1]\n",
    "    cv2.cvtColor(im_arr, cv2.COLOR_BGR2RGB)\n",
    "    #cv2.imwrite(\"/out/face_\"+str(person)+\".jpg\",im_arr)\n",
    "    image_box = Image.fromarray(im_arr)\n",
    "    display(image_box)\n",
    "    time.sleep(2)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
