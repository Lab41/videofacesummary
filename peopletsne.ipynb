{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from collections import namedtuple,defaultdict\n",
    "from bokeh.plotting import figure, output_notebook, output_file, show\n",
    "from ipywidgets import fixed, interact, interact_manual, interactive\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.manifold import TSNE\n",
    "from face import face\n",
    "import face_recognition_models\n",
    "import pickle\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retImg(in_img):\n",
    "    s = in_img.shape\n",
    "    x = s[0]\n",
    "    y = s[1]\n",
    "    img = np.empty((x, y), dtype=np.uint32)\n",
    "    view = img.view(dtype=np.uint8).reshape((x, y, 4))\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            val = in_img[x-i-1,j]\n",
    "            view[i, j, 0] = val[2]\n",
    "            view[i, j, 1] = val[1]\n",
    "            view[i, j, 2] = val[0]\n",
    "            view[i, j, 3] = 255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#point this to a directory of directories containing example cropped images of ppl of interest\n",
    "def make_tasking(lookupdir,outfilename):\n",
    "    tasking = defaultdict(dict)\n",
    "    for tdir in glob.glob(lookupdir):\n",
    "        encodings = []\n",
    "        pics = []\n",
    "        print(tdir)\n",
    "        for qfile in glob.glob(os.path.join(tdir,'*')):\n",
    "            face_image = cv2.imread(qfile)\n",
    "            locs = face.face_locations(face_image)\n",
    "            enc = face.face_encodings(face_image, None)\n",
    "            if enc and len(enc) >=1:\n",
    "                print(qfile)\n",
    "                top, right, bottom, left = locs[0]\n",
    "                encodings.append(face.face_encodings(face_image, None)[0])\n",
    "                cv2.rectangle(face_image, (left, top),\n",
    "                              (right, bottom), (0, 255, 0), 2)\n",
    "                pics.append(face_image[top:bottom, left:right])\n",
    "        key = tdir.split('/')[-1]\n",
    "        tasking[key]['face_vec']= encodings\n",
    "        tasking[key]['pic'] = pics\n",
    "    pickle.dump(tasking,open(outfilename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compile the pickles into something to hand to tsne for viz\n",
    "def make_datastore(people,tasking=None):\n",
    "\n",
    "    X = list()\n",
    "    COLOR = list()\n",
    "    IMG = list()\n",
    "    dw = list()\n",
    "    dh = list()\n",
    "\n",
    "    for p in people:\n",
    "        dat = people[p]['face_vec']\n",
    "        COLOR.append('black')\n",
    "        X.append(dat)\n",
    "        IMG.append(retImg(people[p]['pic']))\n",
    "        dw.append(10)\n",
    "        dh.append(10)\n",
    "    \n",
    "    idx=0\n",
    "    if tasking is not None:\n",
    "        for p in tasking:\n",
    "            colors= ['aliceblue', 'antiquewhite', 'aqua', 'aquamarine', 'azure', 'beige', 'bisque', 'black', 'blanchedalmond', 'blue', 'blueviolet', 'brown', 'burlywood', 'cadetblue', 'chartreuse', 'chocolate', 'coral', 'cornflowerblue', 'cornsilk', 'crimson', 'cyan', 'darkblue', 'darkcyan', 'darkgoldenrod', 'darkgray', 'darkgreen', 'darkkhaki', 'darkmagenta', 'darkolivegreen', 'darkorange', 'darkorchid', 'darkred', 'darksalmon', 'darkseagreen', 'darkslateblue', 'darkslategray', 'darkturquoise', 'darkviolet', 'deeppink', 'deepskyblue', 'dimgray', 'dodgerblue', 'firebrick', 'floralwhite', 'forestgreen', 'fuchsia', 'gainsboro', 'ghostwhite', 'gold', 'goldenrod', 'gray', 'green', 'greenyellow', 'honeydew', 'hotpink', 'indianred ', 'indigo ', 'ivory', 'khaki', 'lavender', 'lavenderblush', 'lawngreen', 'lemonchiffon', 'lightblue', 'lightcoral', 'lightcyan', 'lightgoldenrodyellow', 'lightgray', 'lightgreen', 'lightpink', 'lightsalmon', 'lightseagreen', 'lightskyblue', 'lightslategray', 'lightsteelblue', 'lightyellow', 'lime', 'limegreen', 'linen', 'magenta', 'maroon', 'mediumaquamarine', 'mediumblue', 'mediumorchid', 'mediumpurple', 'mediumseagreen', 'mediumslateblue', 'mediumspringgreen', 'mediumturquoise', 'mediumvioletred', 'midnightblue', 'mintcream', 'mistyrose', 'moccasin', 'navajowhite', 'navy', 'oldlace', 'olive', 'olivedrab', 'orange', 'orangered', 'orchid', 'palegoldenrod', 'palegreen', 'paleturquoise', 'palevioletred', 'papayawhip', 'peachpuff', 'peru', 'pink', 'plum', 'powderblue', 'purple', 'rebeccapurple', 'red', 'rosybrown', 'royalblue', 'saddlebrown', 'salmon', 'sandybrown', 'seagreen', 'seashell', 'sienna', 'silver', 'skyblue', 'slateblue', 'slategray', 'snow', 'springgreen', 'steelblue', 'tan', 'teal', 'thistle', 'tomato', 'turquoise', 'violet', 'wheat', 'white', 'whitesmoke', 'yellow', 'yellowgreen']\n",
    "\n",
    "            for x in tasking[p]['face_vec']:\n",
    "                COLOR.append(colors[idx % len(colors)])\n",
    "                X.append(x)\n",
    "\n",
    "            for x in tasking[p]['pic']:\n",
    "                IMG.append(retImg(x))\n",
    "                dw.append(10)\n",
    "                dh.append(10)\n",
    "            idx +=1\n",
    "    return(X,COLOR,IMG,dw,dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot dots where faces are, black dots for video data, colored dots for people of interest\n",
    "def tsne_faces(prep,X,COLOR,lr,d):\n",
    "    model = TSNE(n_components=2, random_state=234)\n",
    "    model.perplexity = prep\n",
    "    model.learning_rate = lr\n",
    "    d['prep']=prep\n",
    "    d['lr']=lr\n",
    "    np.set_printoptions(suppress=False)\n",
    "    out= model.fit_transform(X) \n",
    "    # plot the result\n",
    "    vis_x = out[:, 0]\n",
    "    vis_y = out[:, 1]\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.scatter(vis_x, vis_y, c=COLOR)\n",
    "    plt.show()\n",
    "    return (prep,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot pictures blue frame is video data, green frame is where a query is\n",
    "def tsne_html(datastore,d,spread=50):\n",
    "    X,COLOR,IMG,dw,dh = DATASTORE\n",
    "    model = TSNE(n_components=2, random_state=234)\n",
    "    model.perplexity=d['prep']\n",
    "    model.learning_rate = d['lr']\n",
    "    np.set_printoptions(suppress=False)\n",
    "    out= model.fit_transform(X) \n",
    "    # plot the result\n",
    "    vis_x = out[:, 0]*spread\n",
    "    vis_y = out[:, 1]*spread\n",
    "    \n",
    "    p = figure(plot_width=800, plot_height=800, x_range=(-80, 80), y_range=(-80,80))\n",
    "\n",
    "    p.image_rgba(image=IMG , x=vis_x , y=vis_y , dw=dw , dh=dh )\n",
    "\n",
    "    show(p)\n",
    "    #output_file(\"faces.html\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makestats(items):\n",
    "    labels=[]\n",
    "    detections=0\n",
    "    for item in items:\n",
    "        detections += item[1]\n",
    "        labels.append(item[0])\n",
    "    return 'labels:{0} detections:{1}'.format(labels,detections)\n",
    "\n",
    "def showResults(threshold,key, tasking ,people):\n",
    "    found = list()\n",
    "    uniq = set()\n",
    "    #for enc in encodings:\n",
    "    #print(type(all_enc),type(sensativity))\n",
    "    for enc in tasking[key]['face_vec']:\n",
    "        for candidate in people:\n",
    "            c_enc = people[candidate]['face_vec']\n",
    "            c_pic = people[candidate]['pic']\n",
    "            c_tim = people[candidate]['times']\n",
    "            dist = face.face_distance([enc],c_enc)\n",
    "            if dist < threshold:\n",
    "                #print ('candidate:{0} detections:{1} dist:{2:0.3}'.format(candidate,len(c_tim),dist[0]))\n",
    "                RGB_img = cv2.cvtColor(c_pic, cv2.COLOR_BGR2RGB)\n",
    "                if candidate not in uniq:\n",
    "                    uniq.add(candidate)\n",
    "                    found.append((candidate,len(c_tim),dist[0],RGB_img))\n",
    "    \n",
    "    side = math.ceil(math.sqrt(len(found)))\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sorted_by_distance = sorted(found, key=lambda tup: tup[2])\n",
    "    \n",
    "    stats = makestats(sorted_by_distance)\n",
    "\n",
    "    for idx, f in enumerate(sorted_by_distance):\n",
    "        plt.subplot(side,side,idx+1)\n",
    "        plt.title(\"label:{0} dist:{1:02.3} det:{2:03}\".format(f[0],f[2],f[1]))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(PIL.Image.fromarray(f[3]))\n",
    "    print(stats)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "people = pickle.load(open('face_detected.pickle','rb'))\n",
    "tasking = pickle.load(open('find_us.pickle','rb'))\n",
    "\n",
    "#pretend you have ppl of interest\n",
    "#DATASTORE = make_datastore(people,tasking)\n",
    "\n",
    "#pretend you just have video processed\n",
    "DATASTORE = make_datastore(people)\n",
    "d = dict()\n",
    "d['prep']=18\n",
    "d['lr']=21\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot dots\n",
    "chain = interact(tsne_faces,\n",
    "         prep=widgets.IntSlider(min=1,max=100,step=1,value=6),\n",
    "         X=fixed(DATASTORE[0]),\n",
    "         COLOR=fixed(DATASTORE[1]),\n",
    "         lr=widgets.IntSlider(min=1,max=1000,step=1,value=70),\n",
    "         d=fixed(d));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot images\n",
    "#prep=18, lr=21\n",
    "output_notebook()\n",
    "tsne_html(DATASTORE,d,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_tasking('/in/1/*','/tasking.pickl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasking = pickle.load(open('/tasking.pickl','rb'))\n",
    "tasking_key = list(tasking.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(showResults, \n",
    "         threshold=widgets.FloatSlider(min=0.00,max=1.0,step=0.01,value=0.42),\n",
    "         key=tasking_key,\n",
    "         tasking=fixed(tasking),people=fixed(people))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "53f01bf7f2264e5cb4880c1e6fdfcb0b": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
