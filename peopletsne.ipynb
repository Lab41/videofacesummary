{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from collections import namedtuple,defaultdict\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from ipywidgets import fixed, interact, interact_manual, interactive\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.manifold import TSNE\n",
    "from face import face\n",
    "import face_recognition_models\n",
    "import pickle\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "import glob\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retImg(in_img):\n",
    "    s = in_img.shape\n",
    "    x = s[0]\n",
    "    y = s[1]\n",
    "    img = np.empty((x, y), dtype=np.uint32)\n",
    "    view = img.view(dtype=np.uint8).reshape((x, y, 4))\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            val = in_img[x-i-1,y-j-1]\n",
    "            view[i, j, 0] = val[2]\n",
    "            view[i, j, 1] = val[1]\n",
    "            view[i, j, 2] = val[0]\n",
    "            view[i, j, 3] = 255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#point this to a directory of directories containing example cropped images of ppl of interest\n",
    "def make_tasking(lookupdir,outfilename):\n",
    "    tasking = defaultdict(dict)\n",
    "    for tdir in glob.glob(lookupdir):\n",
    "        encodings = []\n",
    "        pics = []\n",
    "        print(tdir)\n",
    "        for qfile in glob.glob(os.path.join(tdir,'*')):\n",
    "            face_image = cv2.imread(qfile)\n",
    "            locs = face.face_locations(face_image)\n",
    "            enc = face.face_encodings(face_image, None)\n",
    "            if enc and len(enc) >=1:\n",
    "                print(qfile)\n",
    "                top, right, bottom, left = locs[0]\n",
    "                encodings.append(face.face_encodings(face_image, None)[0])\n",
    "                cv2.rectangle(face_image, (left, top),\n",
    "                              (right, bottom), (0, 255, 0), 2)\n",
    "                pics.append(face_image[top:bottom, left:right])\n",
    "        key = tdir.split('/')[-1]\n",
    "        tasking[key]['enc']= encodings\n",
    "        tasking[key]['pic'] = pics\n",
    "    pickle.dump(tasking,open(outfilename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compile the pickles into something to hand to tsne for viz\n",
    "def make_datastore(people,tasking=None):\n",
    "\n",
    "    X = list()\n",
    "    COLOR = list()\n",
    "    IMG = list()\n",
    "    dw = list()\n",
    "    dh = list()\n",
    "\n",
    "    for p in people:\n",
    "        dat = people[p]['face_vec']\n",
    "        COLOR.append('black')\n",
    "        X.append(dat)\n",
    "        IMG.append(retImg(people[p]['pic']))\n",
    "        dw.append(10)\n",
    "        dh.append(10)\n",
    "    \n",
    "    idx=0\n",
    "    if tasking is not None:\n",
    "        for p in tasking:\n",
    "            colors=['red','green','magenta','blue','orange','purple']\n",
    "\n",
    "            for x in tasking[p]['enc']:\n",
    "                COLOR.append(colors[idx])\n",
    "                X.append(x)\n",
    "\n",
    "            for x in tasking[p]['pic']:\n",
    "                IMG.append(retImg(x))\n",
    "                dw.append(10)\n",
    "                dh.append(10)\n",
    "            idx +=1\n",
    "    return(X,COLOR,IMG,dw,dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot dots where faces are, black dots for video data, colored dots for people of interest\n",
    "def tsne_faces(prep,X,COLOR,lr,d):\n",
    "    model = TSNE(n_components=2, random_state=234)\n",
    "    model.perplexity = prep\n",
    "    model.learning_rate = lr\n",
    "    d['prep']=prep\n",
    "    d['lr']=lr\n",
    "    np.set_printoptions(suppress=False)\n",
    "    out= model.fit_transform(X) \n",
    "    # plot the result\n",
    "    vis_x = out[:, 0]\n",
    "    vis_y = out[:, 1]\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.scatter(vis_x, vis_y, c=COLOR)\n",
    "    plt.show()\n",
    "    return (prep,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot pictures blue frame is video data, green frame is where a query is\n",
    "def tsne_html(datastore,d):\n",
    "    X,COLOR,IMG,dw,dh = DATASTORE\n",
    "    model = TSNE(n_components=2, random_state=234)\n",
    "    model.perplexity=d['prep']\n",
    "    model.learning_rate = d['lr']\n",
    "    np.set_printoptions(suppress=False)\n",
    "    out= model.fit_transform(X) \n",
    "    # plot the result\n",
    "    vis_x = out[:, 0]*50\n",
    "    vis_y = out[:, 1]*50\n",
    "    \n",
    "    p = figure(plot_width=800, plot_height=800, x_range=(-80, 80), y_range=(-80,80))\n",
    "\n",
    "    p.image_rgba(image=IMG , x=vis_x , y=vis_y , dw=dw , dh=dh )\n",
    "\n",
    "    show(p)\n",
    "    #output_file(\"faces.html\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "people = pickle.load(open('persons.pickle','rb'))\n",
    "tasking = pickle.load(open('find_us.pickle','rb'))\n",
    "\n",
    "#pretend you have ppl of interest\n",
    "DATASTORE = make_datastore(people,tasking)\n",
    "\n",
    "#pretend you just have video processed\n",
    "#DATASTORE = make_datastore(people)\n",
    "d = dict()\n",
    "d['prep']=18\n",
    "d['lr']=21\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot dots\n",
    "chain = interact(tsne_faces,\n",
    "         prep=widgets.IntSlider(min=1,max=100,step=1,value=6),\n",
    "         X=fixed(DATASTORE[0]),\n",
    "         COLOR=fixed(DATASTORE[1]),\n",
    "         lr=widgets.IntSlider(min=1,max=1000,step=1,value=70),\n",
    "         d=fixed(d));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot images\n",
    "#prep=18, lr=21\n",
    "tsne_html(DATASTORE,d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {
    "53f01bf7f2264e5cb4880c1e6fdfcb0b": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
