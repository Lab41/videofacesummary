{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "from os.path import join, splitext, isfile\n",
    "from collections import defaultdict\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded bboxes/afghanistan-afghan-people-war-2015-red-cross_0.jpg.dlib_bboxes.pickle\n",
      "Loaded bboxes/afghanistan-afghan-people-war-2015-red-cross_0.jpg.mtcnn_bboxes.pickle\n",
      "Loaded bboxes/afghanistan-afghan-people-war-2015-red-cross_0.jpg.tinyface_bboxes.pickle\n",
      "Loaded bboxes/afghanistan-afghan-people-war-2015-red-cross_0.jpg.frcnn_bboxes.pickle\n"
     ]
    }
   ],
   "source": [
    "''' Note - Use this notebook after you have already processed an image or video with one or more detection \n",
    "algorithms (dlib, mtcnn, tinyface, frcnn). The original media is required in /media and associated bounding \n",
    "box pickle files (ex:\"...dlib_bboxes.pickle\") are required in /bboxes.\n",
    "'''\n",
    "\n",
    "# Enter file name found in /media for image or video that has been processed with one or more detection algorithms\n",
    "media_filename = \"Your_File_Here.jpg\"\n",
    "# dlib=yellow, mtcnn=blue, tinyface=red, frcnn=green\n",
    "detection_methods = [(\"dlib\",(255,255,0)), (\"mtcnn\",(0,0,255)), (\"tinyface\",(255,0,0)),(\"frcnn\",(0,255,0))]\n",
    "\n",
    "results = list()\n",
    "# Load pickle output files from detection algorithms\n",
    "for detection_method in detection_methods:\n",
    "        bbox_filename = join(\"/bboxes\",media_filename + \".\" + detection_method[0]+\"_bboxes.pickle\")\n",
    "        if isfile(bbox_filename):\n",
    "            results.append((pickle.load(open(bbox_filename,\"rb\"))[2],detection_method[1]))\n",
    "            print(\"Loaded {0}\".format(bbox_filename))\n",
    "\n",
    "if len(results) == 0:\n",
    "    print(\"No detection bounding box files found for {0}\".format(media_filename))\n",
    "    \n",
    "# Build a dictionary to look up frames in videos and get detected bounding boxes\n",
    "frame_to_bbox = defaultdict(list)\n",
    "for result in results:\n",
    "    frame_box_list, color = result\n",
    "    for frame_box in frame_box_list:\n",
    "        frame_num, boxes = frame_box\n",
    "        frame_to_bbox[frame_num].append((boxes,color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_detections(media_filename, frame_index, frame_to_bbox):\n",
    "    \n",
    "    ext = splitext(media_filename)[1]\n",
    "\n",
    "    # videos\n",
    "    if ext in ['.avi', '.mov', '.mp4']:            \n",
    "        cap = cv2.VideoCapture(join(\"/media\",media_filename))        \n",
    "        this_frame = list(frame_to_bbox.keys())[frame_index]      \n",
    "        print(\"Selected Frame: {0}\".format(this_frame))\n",
    "        cap.set(1, this_frame)\n",
    "        ret, test_image = cap.read()\n",
    "        test_image = cv2.cvtColor(test_image,cv2.COLOR_BGR2RGB)\n",
    "        if ret:\n",
    "            for bbox_list, color in frame_to_bbox[this_frame]:\n",
    "                for box in bbox_list:\n",
    "                    t,r,b,l = box\n",
    "                    cv2.rectangle(test_image,(l,b),(r,t),color, 2)\n",
    "        else:\n",
    "            print(\"Couldn't retrieve frame number {0}\".format(this_frame))\n",
    "        cap.release()\n",
    "\n",
    "    # images\n",
    "    elif ext in ['.jpg', '.png', '.jpeg', '.bmp', '.gif']:\n",
    "        # Load image and convert to RGB\n",
    "        test_image = cv2.imread(join(\"/media\",media_filename))\n",
    "        test_image = cv2.cvtColor(test_image,cv2.COLOR_BGR2RGB)\n",
    "        for result in results:\n",
    "            frame_box_list, color = result \n",
    "            frame_num, boxes = frame_box_list[0]\n",
    "            for box in boxes:\n",
    "                t,r,b,l = box\n",
    "                cv2.rectangle(test_image,(l,b),(r,t),color, 2)\n",
    "\n",
    "    # unknown extension\n",
    "    else:\n",
    "        print(\"Unknown file extension {0}\".format(ext))\n",
    "\n",
    "    image_box = Image.fromarray(test_image)\n",
    "    display(image_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(show_detections,\n",
    "         media_filename=fixed(media_filename),\n",
    "         frame_index=widgets.IntSlider(min=0,max=len(frame_to_bbox.keys())-1,step=1,value=0),\n",
    "         frame_to_bbox=fixed(frame_to_bbox));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
